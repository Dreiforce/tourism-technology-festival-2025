{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fdd060-bcb8-4a5b-a760-55632a512819",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Instructions for Using the STAC API Extensions: query with more than one operator, sort, fields\n",
    "\n",
    "This notebook provides a step-by-step guide on how to use the STAC (SpatioTemporal Asset Catalog) API to search for Sentinel-2 Level 2A data within a specified time range and geographic area. It demonstrates how to leverage STAC extensions for filtering, selecting, and sorting data based on specific parameters.\n",
    "\n",
    "In the presented example, we will choose the Austrian Central Alps as the study area, focusing on the period from December 2017 to July 2018, in order to illustrate the process of snowmelt in mountainous regions, assuming low cloud cover to ensure the visualizations are clear and readable.\n",
    "\n",
    "In this case, we will show how to use the `query` extension to construct the appropriate parameters for selecting data based on both cloud cover and snow cover conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce230dec-64d3-45c3-bf27-2a3bce7ccd60",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "First, ensure all required packages are installed and imported."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:22.636951Z",
     "start_time": "2025-11-08T21:09:21.093739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pystac_client\n",
    "import geogif\n",
    "import stackstac\n",
    "import os"
   ],
   "id": "b53a2aec8b8d77d3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "21f6e7af-2225-47cf-a94e-b339d7207eee",
   "metadata": {},
   "source": [
    "* `pystac_client`, `stackstack`: A Python library for working with STAC catalogs. It enables interaction with STAC services, reading catalog information, and searching for products based on specified parameters.\n",
    "* `geogif`: A Python library for creating animated GIFs from data cubes, enabling the visualization of time series data in a dynamic and engaging format.\n",
    "* `os`: A standard Python package that provides functionality for interacting with the operating system, including accessing environment variables and managing file paths. It is often used for authentication and setting up access credentials for various APIs and services, such as STAC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b39bd9-0f65-4a92-ac3b-dc5c1cdf248e",
   "metadata": {},
   "source": [
    "## S3 Credentials\n",
    "\n",
    "In order to access the data from CloudFerro's catalog, authentication is required. To facilitate this, you will need to create an account in the Copernicus Data Space Ecosystem (CDSE). The registration process is quick and can be completed in under 60 seconds. You can find the registration link here: https://documentation.dataspace.copernicus.eu/APIs/S3.html.\n",
    "\n",
    "Once you have created an account, the same URL will redirect you to the section where you can generate your `S3 Credentials`. To do this, simply click the `Add Credential` button. This will allow you to define an expiration date for your credentials.\n",
    "\n",
    "After selecting the expiration date, you will have successfully created your own S3 credentials. Please make sure to save the secret key at this point, as it will not be displayed again.\n",
    "\n",
    "Now that you have your S3 credentials, you can use them to connect to the STAC catalog. By utilizing the `os` package, you will set environment variables to authenticate yourself as a valid user for the S3 protocol.\n",
    "\n",
    "The only variables you need to configure are:\n",
    "* `AWS_ACCESS_KEY_ID`\n",
    "* `AWS_SECRET_ACCESS_KEY`."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:22.646229Z",
     "start_time": "2025-11-08T21:09:22.644256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ[\"GDAL_HTTP_TCP_KEEPALIVE\"] = \"YES\"\n",
    "os.environ[\"AWS_S3_ENDPOINT\"] = \"eodata.dataspace.copernicus.eu\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"test\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"test\"\n",
    "os.environ[\"AWS_HTTPS\"] = \"YES\"\n",
    "os.environ[\"AWS_VIRTUAL_HOSTING\"] = \"FALSE\"\n",
    "os.environ[\"GDAL_HTTP_UNSAFESSL\"] = \"YES\""
   ],
   "id": "950660adb2ca24d4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "1bb05d26-29bc-4562-bebf-52bdbcf55e9f",
   "metadata": {},
   "source": [
    "## Connecting to the STAC Catalog\n",
    "\n",
    "We connect to the Copernicus STAC catalog, available at the endpoint: https://stac.dataspace.copernicus.eu/v1."
   ]
  },
  {
   "cell_type": "code",
   "id": "831db1d3-02c3-401f-98c1-bd07eb3c1c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:23.865665Z",
     "start_time": "2025-11-08T21:09:22.656147Z"
    }
   },
   "source": [
    "URL = \"https://stac.dataspace.copernicus.eu/v1\"\n",
    "cat = pystac_client.Client.open(URL)\n",
    "cat.add_conforms_to(\"ITEM_SEARCH\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "3e75f669-5fa5-49c7-91d6-3dbc0324f957",
   "metadata": {},
   "source": [
    "## Defining the Area of Interest (AOI)\n",
    "\n",
    "We define the area as a polygon based on geographical coordinates in GeoJSON format.\n",
    "* `type`: Geometry type, in this case, a polygon.\n",
    "* `coordinates`: A list of coordinates defining the area."
   ]
  },
  {
   "cell_type": "code",
   "id": "e33d75a7-059a-4a58-b41a-dc76624e298f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:23.915181Z",
     "start_time": "2025-11-08T21:09:23.913361Z"
    }
   },
   "source": [
    "geom = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [10.9, 46.8],\n",
    "            [11.3, 46.8],\n",
    "            [11.3, 47.0],\n",
    "            [10.9, 47.0],\n",
    "            [10.9, 46.8],\n",
    "        ]\n",
    "    ],\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "86ebf7ee-e7bd-4451-ab06-5d9c21c72cfc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Defining Search Parameters\n",
    "\n",
    "In this section, we define and combine parameters into a single dictionary for passing to the search function:\n",
    "* `max_items`: The maximum number of results to retrieve.\n",
    "* `collections`: The STAC collection (e.g., Sentinel-2 Level 2A data).\n",
    "* `datetime`: Time range in YYYY-MM-DD/YYYY-MM-DD format.\n",
    "* `intersects`: The previously defined area of interest.\n",
    "* `query`: Typically a key-value pair where the key represents a specific property (e.g., eo:cloud_cover), and the value is the condition or comparison being applied.\n",
    "* `sortby`: Sorts results (e.g., by the eo:cloud_cover property in ascending order).\n",
    "* `fields`: Specifies which fields to exclude (e.g., geometry)."
   ]
  },
  {
   "cell_type": "code",
   "id": "e0c41bf5-af5c-4b5c-91d6-713a79d1842f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:23.926258Z",
     "start_time": "2025-11-08T21:09:23.924365Z"
    }
   },
   "source": [
    "params = {\n",
    "    \"max_items\": 100,\n",
    "    \"collections\": \"sentinel-2-l2a\",\n",
    "    \"datetime\": \"2017-12-01/2018-07-30\",\n",
    "    \"intersects\": geom,\n",
    "    \"query\": {\"eo:cloud_cover\": {\"lte\": 10}, \"eo:snow_cover\": {\"gte\": 0, \"lte\": 100}},\n",
    "    \"sortby\": \"properties.eo:snow_cover\",\n",
    "    \"fields\": {\"exclude\": [\"geometry\"]},\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "7c094db5-aa5e-4067-80ca-62a8731737ed",
   "metadata": {},
   "source": [
    "## Searching the Catalog\n",
    "\n",
    "We query the catalog and convert the results into a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "id": "074c8ef4-4586-42a7-9e15-af7a85cfe336",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:26.391644Z",
     "start_time": "2025-11-08T21:09:23.942970Z"
    }
   },
   "source": [
    "items = list(cat.search(**params).items_as_dicts())"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "1e4e7539-56e0-4deb-bb2b-8ae9585eb200",
   "metadata": {},
   "source": [
    "## Creating DataCube from STAC\n",
    "\n",
    "After performing the search, we can create a STACK object from the obtained items. In the definition of the STACK object, the following parameters must be declared:\n",
    "\n",
    "* `items`: The STAC items that will be included in the stack object.\n",
    "* `resolution`: The desired output resolution.\n",
    "* `bounds_latlon`: The spatial bounding box of the output, given in degrees of latitude and longitude.\n",
    "* `chunksize`: The chunk size to be used for the Dask array.\n",
    "* `epsg`: The EPSG code for the coordinate reference system to which the data will be reprojected.\n",
    "* `gdal_env`: GDAL configuration options to be used when opening and reading the datasets."
   ]
  },
  {
   "cell_type": "code",
   "id": "8f88f7bf-0cf1-458e-bf8c-9eb98638dba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:26.424588Z",
     "start_time": "2025-11-08T21:09:26.401670Z"
    }
   },
   "source": [
    "stack = stackstac.stack(\n",
    "    items=items,\n",
    "    resolution=(20, 20),\n",
    "    bounds_latlon=(10.550, 47.200, 10.850, 47.400),\n",
    "    chunksize=98304,\n",
    "    epsg=32634,\n",
    "    gdal_env=stackstac.DEFAULT_GDAL_ENV.updated(\n",
    "        {\n",
    "            \"GDAL_NUM_THREADS\": -1,\n",
    "            \"GDAL_HTTP_UNSAFESSL\": \"YES\",\n",
    "            \"GDAL_HTTP_TCP_KEEPALIVE\": \"YES\",\n",
    "            \"AWS_VIRTUAL_HOSTING\": \"FALSE\",\n",
    "            \"AWS_HTTPS\": \"YES\",\n",
    "        }\n",
    "    ),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "fd6dbfae-bde8-4ece-afa5-f8557606c52b",
   "metadata": {},
   "source": [
    "## Band selection\n",
    "\n",
    "In this step, we are selecting the specific spectral bands from the stacked satellite data that correspond to the Red, Green, and Blue (RGB) channels. These bands are essential for creating a true-color composite image, which represents the Earthâ€™s surface in a way similar to how it would appear to the human eye.\n",
    "\n",
    "The bands we select to be used to create an RGB image for visualisation, are:\n",
    "* `B04_20m`: Red band\n",
    "* `B03_20m`: Green band\n",
    "* `B02_20m`: Blue band"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b5d0166-8af1-41ee-abb6-4af1ba407788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:26.433615Z",
     "start_time": "2025-11-08T21:09:26.429924Z"
    }
   },
   "source": [
    "rgb = stack.sel(band=[\"B04_20m\", \"B03_20m\", \"B02_20m\"])"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "486e6554-69c5-4de2-9e7d-32842b82e26f",
   "metadata": {},
   "source": [
    "## Displaying results as a GIF\n",
    "\n",
    "In this step, we create a GIF to visualize the filtered results. We obtain a sequence of images ordered by date in ascending order, presenting how the snow cover in the selected region of Alps changed during the specified time period with cloud cover less than 10%."
   ]
  },
  {
   "cell_type": "code",
   "id": "aedc36bc-aca1-461f-af1d-c84fa361f548",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:09:55.190422Z",
     "start_time": "2025-11-08T21:09:26.437136Z"
    }
   },
   "source": [
    "gif = geogif.dgif(rgb, fps=1).compute()\n",
    "gif"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error reading Window(col_off=0, row_off=0, width=1282, height=1262) from 's3://eodata/Sentinel-2/MSI/L2A_N0500/2018/01/29/S2A_MSIL2A_20180129T101251_N0500_R022_T32TPT_20230904T215802.SAFE/GRANULE/L2A_T32TPT_A013604_20180129T101247/IMG_DATA/R20m/T32TPT_20180129T101251_B03_20m.jp2': RasterioIOError('Read failed. See previous exception for details.')",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m: Stream too short\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m: opj_get_decoded_tile() failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m: T32TPT_20180129T101251_B03_20m.jp2, band 1: IReadBlock failed at X offset 1, Y offset 3: opj_get_decoded_tile() failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio/_io.pyx:969\u001B[39m, in \u001B[36mrasterio._io.DatasetReaderBase._read\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio/_io.pyx:199\u001B[39m, in \u001B[36mrasterio._io.io_multi_band\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio/_io.pyx:205\u001B[39m, in \u001B[36mrasterio._io.io_multi_band\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio/_err.pyx:325\u001B[39m, in \u001B[36mrasterio._err.StackChecker.exc_wrap_int\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m: IReadBlock failed at X offset 0, Y offset 0: T32TPT_20180129T101251_B03_20m.jp2, band 1: IReadBlock failed at X offset 1, Y offset 3: opj_get_decoded_tile() failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRasterioIOError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/tourism-technology-festival-2025--cCiOrp7-py3.13/lib/python3.13/site-packages/stackstac/rio_reader.py:385\u001B[39m, in \u001B[36mAutoParallelRioReader.read\u001B[39m\u001B[34m(self, window, **kwargs)\u001B[39m\n\u001B[32m    384\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m385\u001B[39m     result = \u001B[43mreader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m        \u001B[49m\u001B[43mout_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmasked\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# ^ NOTE: we always do a masked array, so we can safely apply scales and offsets\u001B[39;49;00m\n\u001B[32m    390\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# without potentially altering pixels that should have been the ``fill_value``\u001B[39;49;00m\n\u001B[32m    391\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/tourism-technology-festival-2025--cCiOrp7-py3.13/lib/python3.13/site-packages/stackstac/rio_reader.py:104\u001B[39m, in \u001B[36mSingleThreadedRioDataset.read\u001B[39m\u001B[34m(self, window, **kwargs)\u001B[39m\n\u001B[32m    103\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock, \u001B[38;5;28mself\u001B[39m.env.read:\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio/_warp.pyx:1336\u001B[39m, in \u001B[36mrasterio._warp.WarpedVRTReaderBase.read\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio/_io.pyx:644\u001B[39m, in \u001B[36mrasterio._io.DatasetReaderBase.read\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio/_io.pyx:972\u001B[39m, in \u001B[36mrasterio._io.DatasetReaderBase._read\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mRasterioIOError\u001B[39m: Read failed. See previous exception for details.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m gif = \u001B[43mgeogif\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdgif\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrgb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfps\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m gif\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/tourism-technology-festival-2025--cCiOrp7-py3.13/lib/python3.13/site-packages/dask/base.py:373\u001B[39m, in \u001B[36mDaskMethodsMixin.compute\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m    349\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute\u001B[39m(\u001B[38;5;28mself\u001B[39m, **kwargs):\n\u001B[32m    350\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute this dask collection\u001B[39;00m\n\u001B[32m    351\u001B[39m \n\u001B[32m    352\u001B[39m \u001B[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    371\u001B[39m \u001B[33;03m    dask.compute\u001B[39;00m\n\u001B[32m    372\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m373\u001B[39m     (result,) = \u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraverse\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    374\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/tourism-technology-festival-2025--cCiOrp7-py3.13/lib/python3.13/site-packages/dask/base.py:681\u001B[39m, in \u001B[36mcompute\u001B[39m\u001B[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001B[39m\n\u001B[32m    678\u001B[39m     expr = expr.optimize()\n\u001B[32m    679\u001B[39m     keys = \u001B[38;5;28mlist\u001B[39m(flatten(expr.__dask_keys__()))\n\u001B[32m--> \u001B[39m\u001B[32m681\u001B[39m     results = \u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexpr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    683\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m repack(results)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/tourism-technology-festival-2025--cCiOrp7-py3.13/lib/python3.13/site-packages/stackstac/to_dask.py:189\u001B[39m, in \u001B[36mfetch_raster_window\u001B[39m\u001B[34m(reader_table, slices, dtype, fill_value)\u001B[39m\n\u001B[32m    182\u001B[39m \u001B[38;5;66;03m# Only read if the window we're fetching actually overlaps with the asset\u001B[39;00m\n\u001B[32m    183\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m windows.intersect(current_window, asset_window):\n\u001B[32m    184\u001B[39m     \u001B[38;5;66;03m# NOTE: when there are multiple assets, we _could_ parallelize these reads with our own threadpool.\u001B[39;00m\n\u001B[32m    185\u001B[39m     \u001B[38;5;66;03m# However, that would probably increase memory usage, since the internal, thread-local GDAL datasets\u001B[39;00m\n\u001B[32m    186\u001B[39m     \u001B[38;5;66;03m# would end up copied to even more threads.\u001B[39;00m\n\u001B[32m    187\u001B[39m \n\u001B[32m    188\u001B[39m     \u001B[38;5;66;03m# TODO when the Reader won't be rescaling, support passing `output` to avoid the copy?\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m     data = \u001B[43mreader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_window\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    191\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m all_empty:\n\u001B[32m    192\u001B[39m         \u001B[38;5;66;03m# Turn `output` from a broadcast-trick array to a real array, so it's writeable\u001B[39;00m\n\u001B[32m    193\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    194\u001B[39m             np.isnan(data)\n\u001B[32m    195\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m np.isnan(fill_value)\n\u001B[32m    196\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m np.equal(data, fill_value)\n\u001B[32m    197\u001B[39m         ).all():\n\u001B[32m    198\u001B[39m             \u001B[38;5;66;03m# Unless the data we just read is all empty anyway\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/tourism-technology-festival-2025--cCiOrp7-py3.13/lib/python3.13/site-packages/stackstac/rio_reader.py:399\u001B[39m, in \u001B[36mAutoParallelRioReader.read\u001B[39m\u001B[34m(self, window, **kwargs)\u001B[39m\n\u001B[32m    396\u001B[39m         warnings.warn(msg)\n\u001B[32m    397\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m nodata_for_window(window, \u001B[38;5;28mself\u001B[39m.fill_value, \u001B[38;5;28mself\u001B[39m.dtype)\n\u001B[32m--> \u001B[39m\u001B[32m399\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m    401\u001B[39m \u001B[38;5;66;03m# When the GeoTIFF doesn't have a nodata value, and we're using a VRT, pixels\u001B[39;00m\n\u001B[32m    402\u001B[39m \u001B[38;5;66;03m# outside the dataset don't get properly masked (they're just 0). Using `add_alpha`\u001B[39;00m\n\u001B[32m    403\u001B[39m \u001B[38;5;66;03m# in the `WarpedVRT`, we get an explicit alpha channel, which we use as a mask instead.\u001B[39;00m\n\u001B[32m    404\u001B[39m \u001B[38;5;66;03m# See https://github.com/gjoseph92/stackstac/issues/217.\u001B[39;00m\n\u001B[32m    405\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result.shape[\u001B[32m0\u001B[39m] == \u001B[32m2\u001B[39m:\n",
      "\u001B[31mRuntimeError\u001B[39m: Error reading Window(col_off=0, row_off=0, width=1282, height=1262) from 's3://eodata/Sentinel-2/MSI/L2A_N0500/2018/01/29/S2A_MSIL2A_20180129T101251_N0500_R022_T32TPT_20230904T215802.SAFE/GRANULE/L2A_T32TPT_A013604_20180129T101247/IMG_DATA/R20m/T32TPT_20180129T101251_B03_20m.jp2': RasterioIOError('Read failed. See previous exception for details.')"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "ee2a9431-76f2-4ca2-96ba-78f3d96d7dc5",
   "metadata": {},
   "source": [
    "## Displaying Snow Cover for Results\n",
    "\n",
    "We extract the `eo:snow_cover` values for each item and display them. The previously used `sortby` extension allows for automatic sorting of the results based on the selected parameter, in this case, snow cover."
   ]
  },
  {
   "cell_type": "code",
   "id": "24d226cb-7d35-4175-84bd-e0e0ffdd6711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T21:10:20.475100Z",
     "start_time": "2025-11-08T21:10:20.470144Z"
    }
   },
   "source": [
    "snow_cover_values = [item[\"properties\"][\"eo:snow_cover\"] for item in items]\n",
    "snow_cover_values"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.59,\n",
       " 6.89,\n",
       " 29.89,\n",
       " 34.03,\n",
       " 35.42,\n",
       " 35.9,\n",
       " 39.35,\n",
       " 39.52,\n",
       " 40.87,\n",
       " 42.57,\n",
       " 44.36,\n",
       " 44.55,\n",
       " 44.83,\n",
       " 45.71,\n",
       " 46.19,\n",
       " 46.98,\n",
       " 46.99,\n",
       " 48.32,\n",
       " 49.29,\n",
       " 51.8,\n",
       " 52.55,\n",
       " 55.29,\n",
       " 62.63,\n",
       " 69.95]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
